
from Common.common import *
from Exploit.BaseExploit import *
from Config import config
from concurrent.futures import ThreadPoolExecutor
import requests

'''
待测试的url：
http://lac3.glis.ntnu.edu.tw/theme/default/images/header.jpg/.php
http://ag.toko.edu.tw//templates/bolito-fjt/favicon.ico/.php
http://bba.fib.fju.edu.tw/images/logo.jpg/.php
http://ems.fib.fju.edu.tw/images/logo.jpg/.php
http://tokoaa.toko.edu.tw//templates/beez3/favicon.ico/.php
http://en.fxsh.tyc.edu.tw/img/logo.png/.php
http://yschen.ee.yzu.edu.tw/backgnd.gif/.php
http://eshop.ntnu.edu.tw/images/a.gif/.php
http://ms.fib.fju.edu.tw/images/logo.jpg/.php
http://idsl.yuntech.edu.tw/pic/mbg.gif/.php
http://sts.ym.edu.tw/images/search_btn.jpg/.php
http://ip6959.cm.nsysu.edu.tw/index/logo.jpg/.php


实际存在解析漏洞的url（数量为4）
http://yschen.ee.yzu.edu.tw/backgnd.gif/.php
http://eshop.ntnu.edu.tw/images/a.gif/.php
http://idsl.yuntech.edu.tw/pic/mbg.gif/.php
http://ip6959.cm.nsysu.edu.tw/index/logo.jpg/.php


[
{'parse': '解析漏洞', 'url': 'http://eshop.ntnu.edu.tw/', 'status': 200}, 
{'parse': '解析漏洞', 'url': 'http://lac3.glis.ntnu.edu.tw/', 'status': 200}, 
{'parse': '解析漏洞', 'url': 'http://ip6959.cm.nsysu.edu.tw/', 'status': 200}]
'''


class ParseScan(object):
    def __init__(self, target, clear_task_list):
        # super().__init__()
        self.target = target
        self.clear_task_list = clear_task_list
        self.headers = {'User-Agent': 'Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'}
        self.parsescanlist = []

    def format_url(self, url, path):
        # 这里判断结尾是否存在/符号 如果有进行清除 ，并且拼接rule.py的规则中的路径 再返回一个url
        if url.endswith('/'):
            url = url.strip('/')
        if not path.startswith('/'):
            path = '/' + path + '/.php'
        return url + path

    def write_file(self, web_lists, target, page):
        pass

    def exploit(self, url):
        resp = requests.get(url, headers=self.headers, verify=config.verify_ssl, allow_redirects=config.allow_redirects)
        mycompile = re.compile(r'<img\ssrc="(.*)"\salt', flags=re.S | re.I)
        path = re.search(mycompile, resp.content.decode('utf-8')).group(1)
        url = self.format_url(url, path)
        resp = requests.get(url, headers=self.headers, verify=config.verify_ssl, allow_redirects=config.allow_redirects)
        if 'text/plain' not in resp.headers.get("Content-Type") and resp.status_code == 200:
            parse_dict = {
                'parse': '解析漏洞',
                'url': url,
                'status': resp.status_code
            }
            self.parsescanlist.append(parse_dict)
        '''

        首先是用robots.txt来判断

        正常访问：robots.txt 返回类型为'text/plain'

        存在漏洞的情况下
            访问 robots.txt/.php 返回类型为'text/html'


        parse:
        判断比较来源： 参考w13scan写法

        两种方式
        1、普通gif文件请求返回包的Content-Type为Content-Type: image/gif
            如果存在解析漏洞 请求1.gif/.php 返回包中的Content-Type的Content-Type: text/html

        2、robots.txt来进行请求 robots.txt/.php 同样

        正常robots.txt/.php 结果为Content-Type: text/plain
        存在解析漏洞的结果为 Content-Type: text/html
            判断语句：
            if "user-agent" in r.text.lower() and 'text/plain' not in r.headers.get("Content-Type", ''):
        '''

    def main(self):
        p = ThreadPoolExecutor(10)
        for i in self.clear_task_list:
            # if i['target'] == 'subdomain':
            p.submit(self.exploit, i)
        p.shutdown()
        print(self.parsescanlist)


if __name__ == '__main__':
    a = [
        'http://lac3.glis.ntnu.edu.tw/',
        'http://ag.toko.edu.tw/',
        'http://bba.fib.fju.edu.tw/',
        'http://ems.fib.fju.edu.tw/',
        'http://tokoaa.toko.edu.tw/',
        'http://en.fxsh.tyc.edu.tw/',
        'http://yschen.ee.yzu.edu.tw/',
        'http://eshop.ntnu.edu.tw/',
        'http://ms.fib.fju.edu.tw/',
        'http://idsl.yuntech.edu.tw/',
        'http://sts.ym.edu.tw/',
        'http://ip6959.cm.nsysu.edu.tw/'
    ]

    ParseScan('nbcc.cn', a).main()

